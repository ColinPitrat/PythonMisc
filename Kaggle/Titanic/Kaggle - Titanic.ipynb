{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb0d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0f4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_state = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6441b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m challenge_input_ori \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m all_input_ori \u001b[38;5;241m=\u001b[39m all_data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/python-venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python-venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/python-venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python-venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/python-venv/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"train.csv\")\n",
    "challenge_input_ori = pd.read_csv(\"test.csv\")\n",
    "\n",
    "all_input_ori = all_data.drop('Survived', axis=1)\n",
    "all_labels = all_data['Survived'].copy()\n",
    "\n",
    "# Extract a validation set\n",
    "train_input_ori, validate_input_ori, train_labels, validate_labels = train_test_split(all_input_ori, all_labels, test_size=0.15, random_state=rd_state)\n",
    "\n",
    "# Extract a testing set\n",
    "train_input_ori, test_input_ori, train_labels, test_labels = train_test_split(train_input_ori, train_labels, test_size=0.18, random_state=rd_state)\n",
    "#train_input_ori, test_input_ori, train_labels, test_labels = train_test_split(all_input_ori, all_labels, test_size=0.1, random_state=rd_state)\n",
    "\n",
    "train_both_ori = train_input_ori.copy()\n",
    "train_both_ori['Survived'] = train_labels\n",
    "\n",
    "# Sanity check\n",
    "print(\"All data:  %s\" % (all_data.shape,))\n",
    "print(\"All input: %s\" % (all_input_ori.shape,))\n",
    "print(\"Training:  %s\" % (train_input_ori.shape,))\n",
    "print(\"Test set:  %s\" % (test_input_ori.shape,))\n",
    "#print(\"Validate:  %s\" % (validate_input_ori.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_both_ori.head() )\n",
    "display(train_both_ori.describe())\n",
    "display(test_input_ori.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913634e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "train_both_ori.hist(bins=50, figsize=(20,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d74e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "title_encoder = OneHotEncoder(\n",
    "    categories=[[\"Capt\", \"Col\", \"Dr\", \"Lady\", \"Major\", \"Master\", \"Miss\", \n",
    "                 \"Mlle\", \"Mme\", \"Mr\", \"Mrs\", \"Ms\", \"Rev\", \"the Countess\"]],\n",
    "    handle_unknown='infrequent_if_exist',\n",
    "    min_frequency=1,\n",
    ")\n",
    "embarked_encoder = OneHotEncoder(\n",
    "    categories=[[\"S\", \"C\", \"Q\"]],\n",
    "    handle_unknown='infrequent_if_exist',\n",
    "    min_frequency=1,\n",
    ")\n",
    "\n",
    "all_input_copy = all_input_ori.copy()\n",
    "all_input_copy['Title'] = all_input_copy['Name'].str.split(', ', n=1, expand=True)[1].str.split('.', n=1, expand=True)[0]\n",
    "title_encoder.fit_transform(all_input_copy[[\"Title\"]])\n",
    "embarked_encoder.fit_transform(all_input_copy[[\"Embarked\"]])\n",
    "\n",
    "def enrich_input(some_input_ori):\n",
    "    some_input = some_input_ori.copy()\n",
    "    \n",
    "    # Sex as a number\n",
    "    some_input[\"Male\"] = (some_input[\"Sex\"] == \"male\") * 1.0\n",
    "    \n",
    "    # Age buckets\n",
    "    some_input['Age_2'] = 2*(some_input['Age']//2)\n",
    "    some_input['Age_5'] = 5*(some_input['Age']//5)\n",
    "    some_input['Age_10'] = 10*(some_input['Age']//10)\n",
    "    \n",
    "     # Family size\n",
    "    some_input['FSize'] = some_input['Parch'] + some_input['SibSp']\n",
    "    \n",
    "    # Embarked as a number (Southampton (1) is the departure, then Cherbourg (2) then Queenstown (3))\n",
    "    #some_input[\"Embarked_N\"] = (some_input[\"Embarked\"] == \"Q\") * 3.0 + \\\n",
    "    #                           (some_input[\"Embarked\"] == \"C\") * 2.0 + \\\n",
    "    #                           (some_input[\"Embarked\"] == \"S\") * 1.0\n",
    "        \n",
    "    some_input[\"Estimated_Age\"] = 1.0 * (some_input[\"Age\"] > 1) * (10*some_input[\"Age\"]%10 == 5)\n",
    "    \n",
    "    # Extract and OneHotEncode title\n",
    "    some_input['Title'] = some_input['Name'].str.split(', ', n=1, expand=True)[1].str.split('.', n=1, expand=True)[0]\n",
    "    title_encoded = title_encoder.transform(some_input[['Title']]).toarray()\n",
    "    some_input[title_encoder.get_feature_names_out()] = title_encoded\n",
    "\n",
    "    # OneHotEncode Embarked\n",
    "    embarked_encoded = embarked_encoder.transform(some_input[['Embarked']]).toarray()\n",
    "    some_input[embarked_encoder.get_feature_names_out()] = embarked_encoded\n",
    "    \n",
    "    # Drop non-numerical data\n",
    "    some_input = some_input.drop('Name', axis=1)\n",
    "    some_input = some_input.drop('Sex', axis=1)\n",
    "    some_input = some_input.drop('Ticket', axis=1)\n",
    "    some_input = some_input.drop('Cabin', axis=1)\n",
    "    some_input = some_input.drop('Embarked', axis=1)\n",
    "    some_input = some_input.drop('Title', axis=1)\n",
    "    \n",
    "    return some_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759f28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input = enrich_input(all_input_ori)\n",
    "train_input = enrich_input(train_input_ori)\n",
    "train_both = enrich_input(train_both_ori)\n",
    "test_input = enrich_input(test_input_ori)\n",
    "validate_input = enrich_input(validate_input_ori)\n",
    "challenge_input = enrich_input(challenge_input_ori)\n",
    "\n",
    "# Sanity check\n",
    "print(\" === Originals (unmodified)? ===\")\n",
    "print(\"All data:      %s\" % (all_data.shape,))\n",
    "print(\"All input:     %s\" % (all_input_ori.shape,))\n",
    "print(\"Training:      %s\" % (train_input_ori.shape,))\n",
    "print(\"Train both:    %s\" % (train_both_ori.shape,))\n",
    "print(\"Test set:      %s\" % (test_input_ori.shape,))\n",
    "print(\"Validate:      %s\" % (validate_input_ori.shape,))\n",
    "print(\"Challenge:     %s\" % (challenge_input_ori.shape,))\n",
    "\n",
    "print(\" === Enriched ===\")\n",
    "print(\"All input:     %s\" % (all_input.shape,))\n",
    "print(\"Training:      %s\" % (train_input.shape,))\n",
    "print(\"Train both:    %s\" % (train_both.shape,))\n",
    "print(\"Test set:      %s\" % (test_input.shape,))\n",
    "print(\"Validate:      %s\" % (validate_input.shape,))\n",
    "print(\"Challenge:     %s\" % (challenge_input.shape,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf9c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_both.corr(numeric_only=True))\n",
    "\n",
    "# colormaps: https://matplotlib.org/stable/gallery/color/colormap_reference.html\n",
    "train_both.plot.scatter(\"Age\", \"Fare\", c=\"Survived\", colormap=\"RdYlBu\")\n",
    "\n",
    "#df = pd.crosstab(pd.cut(train_both['Pclass'], 3), train_both['Male'])\n",
    "\n",
    "#df = train_both[['Pclass','Male','Survived', 'PassengerId']] \\\n",
    "#          .groupby(['Pclass','Male','Survived']) \\\n",
    "#          .count().reset_index() \\\n",
    "#          .pivot(columns='Survived', index=['Pclass','Male'])\n",
    "#display(df)\n",
    "#df.plot.bar(stacked=True, color=['r', 'b'])\n",
    "\n",
    "# Doesn't quite work\n",
    "#df = train_both[['Pclass','Male','PassengerId']]\n",
    "#display(df)\n",
    "#df.plot.hist(by=['Pclass','Male'], stacked=True, color=['r','b'])\n",
    "\n",
    "#pd.plotting.scatter_matrix(train_both, figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d01bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_by(column):\n",
    "    df = train_both[[column, 'Survived', 'PassengerId']] \\\n",
    "              .groupby([column, 'Survived']) \\\n",
    "              .count().reset_index() \\\n",
    "              .pivot(columns='Survived', index=[column])\n",
    "    df.plot.bar(stacked=True, color=['r', 'b'])\n",
    "\n",
    "hist_by('Pclass')\n",
    "hist_by('Male')\n",
    "hist_by('Age')\n",
    "hist_by('Age_2')\n",
    "hist_by('Age_5')\n",
    "hist_by('Age_10')\n",
    "hist_by('SibSp')\n",
    "hist_by('Parch')\n",
    "hist_by('Estimated_Age')\n",
    "\n",
    "# TODO: hist_by one hot encoded stuff\n",
    "#hist_by('Title')\n",
    "#hist_by('Embarked')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af165e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(set(train_input[\"PassengerId\"]).intersection(set(test_input[\"PassengerId\"])))\n",
    "display(set(train_input[\"PassengerId\"]).intersection(set(validate_input[\"PassengerId\"])))\n",
    "display(set(test_input[\"PassengerId\"]).intersection(set(validate_input[\"PassengerId\"])))\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14feb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, DotProduct, Exponentiation, ExpSineSquared, Matern, RationalQuadratic, RBF\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import itertools\n",
    "\n",
    "rd = 42\n",
    "\n",
    "\n",
    "all_classifiers = dict()\n",
    "\n",
    "# 0.76: clf = KNeighborsClassifier(3)\n",
    "# 0.77: clf = SVC(kernel=\"linear\", C=0.025, random_state=rd)\n",
    "# 0.74: clf = SVC(gamma=2, C=1, random_state=rd)\n",
    "# 0.74: clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, random_state=rd)\n",
    "# 0.79: clf = RandomForestClassifier(max_depth=3, n_estimators=3, max_features=1, random_state=rd)\n",
    "# 0.78: clf = RandomForestClassifier(max_depth=5, n_estimators=100, max_features=1, random_state=rd)\n",
    "# 0.83: clf = MLPClassifier(alpha=0.1, max_iter=1000, random_state=rd)\n",
    "# 0.77: clf = GaussianProcessClassifier(1.0 * RBF(1.0), random_state=rd)\n",
    "# 0.80: clf = DecisionTreeClassifier(max_depth=3, random_state=rd)\n",
    "# 0.75: clf = AdaBoostClassifier(random_state=rd)\n",
    "# 0.75: clf = GaussianNB()\n",
    "# 0.76: clf = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "for k in range(1, 20):\n",
    "    all_classifiers[\"k-neighbors, k=%s\" % k] = KNeighborsClassifier(k)\n",
    "\n",
    "for k in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]: # linear, poly, rbf, sigmoid, precomputed\n",
    "    for g in [\"scale\", \"auto\", 1, 2, 3, 5]:\n",
    "        for c in [0.025, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]:\n",
    "            all_classifiers[\"svc %s, g=%s, c=%s\" % (k, g, c)] = SVC(kernel=k, gamma=g, C=c, random_state=rd)\n",
    "\n",
    "for d in range(1, 10):\n",
    "    for e in range(1, 10):\n",
    "        for m in range(1, 20):\n",
    "            all_classifiers[\"random-forest, depth=%s, est=%s, max_features=%s\" % (d, e, m)] = \\\n",
    "              RandomForestClassifier(max_depth=d, n_estimators=e, max_features=m, random_state=rd)\n",
    "\n",
    "for s in range(1, 10):\n",
    "    for act in [\"relu\"]:               # identity, relu, logistic, tanh, relu\n",
    "        for solver in [\"lbfgs\"]:       # lbfgs (better for small datasets), sgd or adam\n",
    "            for rate in [\"adaptive\"]:  # constant, invscaling or adaptive\n",
    "                for a in [0.1, 0.5, 1]:\n",
    "                    all_classifiers[\"mlp, sz=%s, act=%s, solver=%s, learn_rate=%s, alpha=%s\" % (s, act, solver, rate, a)] = \\\n",
    "                      MLPClassifier(\n",
    "                       hidden_layer_sizes=(s,),\n",
    "                       activation=act, \n",
    "                       solver=solver,\n",
    "                       learning_rate=rate, \n",
    "                       alpha=a,\n",
    "                       max_iter=2000,\n",
    "                       random_state=rd\n",
    "                      )\n",
    "                    all_classifiers[\"mlp2, sz=%s, act=%s, solver=%s, learn_rate=%s, alpha=%s\" % ((s, s), act, solver, rate, a)] = \\\n",
    "                      MLPClassifier(\n",
    "                       hidden_layer_sizes=(s,s),\n",
    "                       activation=act, \n",
    "                       solver=solver,\n",
    "                       learning_rate=rate, \n",
    "                       alpha=a,\n",
    "                       max_iter=2000,\n",
    "                       random_state=rd\n",
    "                      )\n",
    "\n",
    "for k in [ConstantKernel(), DotProduct(), Exponentiation(RBF(), 2), 1.0 * RBF(1.0), Matern(), RationalQuadratic(alpha_bounds=(1e-5, 1e10))]:\n",
    "    all_classifiers[\"gaussian-process, %s\" % k] = GaussianProcessClassifier(kernel=k, random_state=rd)\n",
    "\n",
    "for d in range(1, 10):\n",
    "    all_classifiers[\"decision-tree, d=%s\" % d] = DecisionTreeClassifier(max_depth=d, random_state=rd)\n",
    "    \n",
    "for d in range(1, 3):\n",
    "    all_classifiers[\"ada-boost, d = %s\" % d] = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=d),\n",
    "                                                                  random_state=rd)\n",
    "    \n",
    "all_classifiers[\"gaussian-nb\"] = GaussianNB()\n",
    "#all_classifiers[\"QDA\"] = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "scl = StandardScaler()\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "\n",
    "max_score = 0\n",
    "max_description = None\n",
    "scored_classifiers = []\n",
    "for description, clf in all_classifiers.items():\n",
    "    try:\n",
    "        pip = make_pipeline(scl, imp, clf)\n",
    "        \n",
    "        #pip.fit(train_input, train_labels)\n",
    "\n",
    "        #test_score = pip.score(test_input, test_labels)        \n",
    "        #validate_score = pip.score(validate_input, validate_labels)\n",
    "        #score = min(test_score, validate_score)\n",
    "        #print(\"%s: %s (%s, %s)\" % (description, score, test_score, validate_score))\n",
    "        \n",
    "        scores = cross_val_score(pip, all_input, all_labels,\n",
    "                                 scoring=make_scorer(balanced_accuracy_score),\n",
    "                                 cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=10,\n",
    "                                                            random_state=rd))\n",
    "        score=scores.mean()\n",
    "        print(\"%s: %s (std: %s)\" % (description, scores.mean(), scores.std()))\n",
    "        \n",
    "        scored_classifiers.append((score, description, pip))\n",
    "        \n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_description = description\n",
    "    \n",
    "            # The model did good, train it on all the data we have\n",
    "            pip.fit(all_input, all_labels)\n",
    "        \n",
    "            challenge_output = pip.predict(challenge_input)\n",
    "            challenge_result = challenge_input.copy()\n",
    "            challenge_result[\"Survived\"] = challenge_output\n",
    "            challenge_result.to_csv(\"cpitrat_result.csv\", columns=[\"PassengerId\", \"Survived\"], index=False)\n",
    "    except e:\n",
    "        print(\"Failed on '%s': %s\" % (description, e))\n",
    "    \n",
    "print(\"Max score for '%s': %s\" % (max_description, max_score))\n",
    "\n",
    "scored_classifiers.sort(key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting of the N best classifiers\n",
    "\n",
    "N = 10\n",
    "\n",
    "estimators = []\n",
    "for s, d, c in scored_classifiers[:N]:\n",
    "    print(\"%s: %s\" % (s, d))\n",
    "    estimators.append((d, c))\n",
    "    \n",
    "v = VotingClassifier(estimators)\n",
    "\n",
    "scores = cross_val_score(v, all_input, all_labels,\n",
    "                         scoring=make_scorer(balanced_accuracy_score),\n",
    "                         cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=10,\n",
    "                                                    random_state=rd))\n",
    "\n",
    "print(\"Voting score: %s (std: %s)\" % (scores.mean(), scores.std()))\n",
    "    \n",
    "v.fit(all_input, all_labels)\n",
    "\n",
    "challenge_output = v.predict(challenge_input)\n",
    "challenge_result = challenge_input.copy()\n",
    "challenge_result[\"Survived\"] = challenge_output\n",
    "challenge_result.to_csv(\"cpitrat_result.csv\", columns=[\"PassengerId\", \"Survived\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71751601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting of the classifiers above a certain score, with max N per type\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "N = 3\n",
    "\n",
    "estimators = []\n",
    "types = defaultdict(int)\n",
    "for s, n, c in scored_classifiers:\n",
    "    t = n.split(',')[0]\n",
    "    if types[t] < N:\n",
    "        types[t] += 1\n",
    "        estimators.append((n, c))\n",
    "        print(\"%s: %s: %s\" % (s, t, n))\n",
    "    if s < 0.8095:\n",
    "        break\n",
    "\n",
    "v = VotingClassifier(estimators)\n",
    "\n",
    "scores = cross_val_score(v, all_input, all_labels,\n",
    "                         scoring=make_scorer(balanced_accuracy_score),\n",
    "                         cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=10,\n",
    "                                                    random_state=rd))\n",
    "\n",
    "print(\"Voting score: %s (std: %s)\" % (scores.mean(), scores.std()))\n",
    "    \n",
    "v.fit(all_input, all_labels)\n",
    "\n",
    "challenge_output = v.predict(challenge_input)\n",
    "challenge_result = challenge_input.copy()\n",
    "challenge_result[\"Survived\"] = challenge_output\n",
    "challenge_result.to_csv(\"cpitrat_result.csv\", columns=[\"PassengerId\", \"Survived\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
